{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe455eb-2b44-4630-a2ec-3d97f80b0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import wooldridge as woo\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecc39ea-1557-41a0-b693-0ae6b7ea9f07",
   "metadata": {},
   "source": [
    "# Week 3 Exercise\n",
    "\n",
    "## Question 1:\n",
    "We want to choose the right specification to create our regression model. For this exercise we will be using the **hprice1** dataset from wooldridge. We will be fitting various models to predict the **price** of a house, starting first using **sqrft** as the predictor. \n",
    "\n",
    "For the first step I would like you to fit several different models:\n",
    "- Linear Model\n",
    "- Quadratic Model\n",
    "\n",
    "Compare the out-of-sample performance by fitting yoru model first on a training set and then calculating the root mean squared error (RMSE) over a testing set where:\n",
    "\n",
    "The formula for Root Mean Square Error (RMSE) is given by:\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - \\hat{y}_i \\right)^2}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $n$ is the number of observations,\n",
    "- $y_i$ is the actual value for the \\(i\\)-th observation,\n",
    "- $\\hat{y}_i$ is the predicted value for the \\(i\\)-th observation\n",
    "\n",
    "The test set should be 30% of your data. **Which model gives the better performance on the test set?**\n",
    "\n",
    "\n",
    "\n",
    "Note that in order to fit a quadratic model you would use a formula that takes the following form\n",
    "y ~ x + I(X**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ae932-f52b-443b-b68d-ad4532b7d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = woo.data('hprice1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85b12ab-1bf7-4be9-8bc7-143bde358cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train, test = train_test_split(___, test_size= __)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccc09b-5484-4342-90ca-49df6dd77985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear model\n",
    "model = smf.ols('___ ~ ___', train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a82c2-7465-4fb3-9548-a54577ff99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the performance on the test set\n",
    "predictions = model.predict(___)\n",
    "\n",
    "# Calculate the RMSE - the code below is a start, but you need to follow the RMSE formula\n",
    "test['price'] - ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34aa0a6-92b8-4d98-8594-194c87cf7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the linear model\n",
    "model = smf.ols('___ ~ ___', train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ca473-0102-4977-9272-9ea89cbf0653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the performance on the test set\n",
    "predictions = model.predict(___)\n",
    "\n",
    "# Calculate the RMSE - the code below is a start, but you need to follow the RMSE formula\n",
    "test['price'] - ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c256659a-5857-4802-bffc-567e05c4771a",
   "metadata": {},
   "source": [
    "## Question 2: What is the confidence interval around your estimates of the coefficients for each predictor in the better model? (Check the summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f69be2f-b276-4163-a4ba-5f345a2a5fa7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "946504c9-68b8-460c-8d89-ef8f1e569c86",
   "metadata": {},
   "source": [
    "## Question 3: We want to generate bootstrap confidence intervals around your estimate of the sqrft variable for the quadratic mode using the following steps:\n",
    "\n",
    "- **Step 1:** Set a number of bootstrap iterations (e.g., 1000). This is how many times you will resample and refit the model.\n",
    "\n",
    "- **Step 2:** For each iteration:\n",
    "  - Randomly sample your data **with replacement**, so the new sample is the same size as the original dataset.\n",
    "  - Fit an OLS regression model using the resampled data, with `price` as the dependent variable and `sqrft` (and its square) as the independent variable.\n",
    "  - Record the estimated coefficient for `sqrft` from the fitted model.\n",
    "\n",
    "- **Step 3:** After running all iterations, you will have a collection of estimated `sqrft` coefficients (one from each bootstrap sample).\n",
    "\n",
    "- **Step 4:** To calculate the 95% confidence interval for the `sqrft` coefficient:\n",
    "  - Sort the bootstrap estimates for the `sqrft` coefficient.\n",
    "  - Identify the 2.5th percentile and the 97.5th percentile of these sorted estimates. These percentiles represent the lower and upper bounds of the 95% bootstrap confidence interval.\n",
    "\n",
    "- **Step 5:** Report the 95% confidence interval for the `sqrft` coefficient.\n",
    "\n",
    "**How do the bootstrap intervals compare to teh ones from the model summary?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6667557-8835-420b-a541-8e382f403de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nboot = ___\n",
    "params = []\n",
    "for i in range(nboot):\n",
    "    # sample with replacement with length = n samples\n",
    "    temp = data.sample(len(data), ___)\n",
    "\n",
    "    # estimate model\n",
    "    temp_model = smf.ols('___ ~ ___', temp).fit()\n",
    "\n",
    "    #extract desired metrics\n",
    "    params.append(temp_model.params['sqrft'])\n",
    "\n",
    "params = pd.Series(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de6c8f-a2e9-4d1e-8335-dda14027a529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower bound \n",
    "print(params.quantile(___))\n",
    "\n",
    "# Upper Bound \n",
    "print(params.quantile(___))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bda7c48-e5f0-4ca3-baad-8d36b2291dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a5ea6-8751-4f49-9b56-2d951fb05b07",
   "metadata": {},
   "source": [
    "Bonus Question: Below I add an unsual value to the dataset, what happens to the bootsrap estimates when this datapoint is added?\n",
    "- What does this tell you about the purpose of bootstrapping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6cc8ba-5ae0-4a74-951e-fb89cd8475df",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = data[['price', 'sqrft']].copy().reset_index(drop = True)\n",
    "\n",
    "# adding a highly influention observation tp the data\n",
    "new = pd.DataFrame({'price': 200, 'sqrft': 5000}, index = [88])\n",
    "case = pd.concat([case, new])\n",
    "\n",
    "model_inf = smf.ols('price ~ sqrft + I(sqrft**2)', case).fit()\n",
    "\n",
    "# we can see the point on our unusual observations plot where the diameter is equal to the \"cooks distance\"\n",
    "import statsmodels.api as sm\n",
    "sm.graphics.influence_plot(model_inf, ax = ax, criterion = 'cooks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3fb15e-c796-4f7e-9025-b4f6c8df3275",
   "metadata": {},
   "outputs": [],
   "source": [
    "case = data[['price', 'sqrft']].copy().reset_index(drop = True)\n",
    "\n",
    "\n",
    "new = pd.DataFrame({'price': 200, 'sqrft': 5000}, index = [88])\n",
    "case = pd.concat([case, new])\n",
    "\n",
    "\n",
    "nboot = ___\n",
    "params = []\n",
    "for i in range(nboot):\n",
    "    # sample with replacement with length = n samples\n",
    "    temp = case.sample(len(case), ___)\n",
    "\n",
    "    # estimate model\n",
    "    temp_model = smf.ols('___ ~ ___', temp).fit()\n",
    "\n",
    "    #extract desired metrics\n",
    "    params.append(temp_model.params['sqrft'])\n",
    "\n",
    "params = pd.Series(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e967e5fa-60f3-4b69-b7c5-4684470b541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d5a2f9-78a9-4cd2-abfa-3fb4f77a8f7b",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Below I give you starting code to generate a 95% prediction and confidence interval using the model you chose as the best in the previous question. \n",
    "\n",
    "- What is the intepretation of the confidence interval here? What about the prediction interval? (Hint: Note the obs_ vs mean_ before the variable names)\n",
    "\n",
    "- What percentage of the observed values fall within the prediction interval?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a94ab-f302-4c00-8f40-2ec10aca4822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we refit the model over the entire data set\n",
    "model = smf.ols('___ ~ ___', data).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ffe611-e4dd-4b9a-9584-fd703ae1ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.get_prediction(data)                       # generate predictions\n",
    "intervals = predictions.summary_frame(alpha = ___)       # compute 95% intervals\n",
    "intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e77c3-452c-4615-8683-05c69920bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should use boolean indexing to find the proportion of observations from the data that fall into the CI\n",
    "((___ < data['price'] ) & (data['price'] < ___)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c250d27-3db3-4bb2-8952-c6814ea60813",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = 'sqrft'\n",
    "y_var = 'price'\n",
    "\n",
    "store = pd.DataFrame({x_var:np.linspace(data[x_var].min(), data[x_var].max(), 1000)})\n",
    "predictions = model.get_prediction(store)                       # generate predictions\n",
    "intervals = predictions.summary_frame(alpha = 0.05)       # compute 95% intervals\n",
    "\n",
    "# Extracting estimated intervals\n",
    "store['point_est'] = intervals['mean']     # point estimates\n",
    "store[['ci_lower', 'ci_upper']] = intervals[['mean_ci_lower', 'mean_ci_upper']]   # lower and upper CONFIDENCE intervals\n",
    "store[['pi_lower', 'pi_upper']] = intervals[['obs_ci_lower', 'obs_ci_upper']]     # lower and upper PREDICTION intervals\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.scatter(x=data[x_var], y=data[y_var], color='black', alpha = .5)\n",
    "plt.plot(store[x_var], store['point_est'], color='blue', label='Fitted line')\n",
    "plt.fill_between(store[x_var], store['ci_lower'], store['ci_upper'], color='royalblue', alpha=0.2, label='Confidence Interval')\n",
    "plt.fill_between(store[x_var], store['pi_lower'], store['pi_upper'], color='lightsteelblue', alpha=0.2, label='Prediction Interval')\n",
    "plt.ylabel(y_var)\n",
    "plt.xlabel(x_var)\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314542c1-6857-4b37-86b7-f712c7bfa079",
   "metadata": {},
   "source": [
    "## Question 5: We will now try to fit a log linear model to the dataset (hint: you will need to use np.log() in the statsmodels formula). Use the formula:\n",
    "$$log(price) = \\beta_1 + \\beta_2 sqrft + e$$\n",
    "\n",
    "- What is the interpretation of the coefficient sqrft for this regression equation?\n",
    "- Does this regression appear to be an improvement on the linear-linear model? How can we tell? (Hint: consider the properties of the regression equation we were interested in improving using a log transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9794bce-aaea-4059-94da-5848bf41ed6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the following code\n",
    "model = smf.ols('__~__', data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6607479e-8db0-4728-b0fc-1e2338cbff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1808b1e-0e55-47cf-9b04-2ce8ca89f35f",
   "metadata": {},
   "source": [
    "## Question 6: Now suppose we would like to investigate whether a power transform on the dependent variable price would be appropriate. \n",
    "Recall the box cox transform takes the form:\n",
    "$$\n",
    "T_{BC}(x,\\lambda) = x^{(\\lambda)}=\\begin{cases}\n",
    "\\frac{x^\\lambda - 1}{\\lambda} \\phantom- \\text{ when }\\lambda \\not= 0, \\\\\n",
    "\\ln(x) \\phantom- \\text{ when }\\lambda = 0.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Where $\\lambda = 0$ is simply a special case of the transform where it is equivalent to a log transform. In teh case that we decide a log-transform may be appropriate, we can use the tools available to us in python to also determine whether a simple log transform is *optimal* or if we can make improvments by changing the value of lambda.\n",
    "\n",
    "- Would a Box_cox transform be appropriate for transforming price? Why or why not?\n",
    "- What does the stats.boxcox function below do? What does the value of \"ci\" tell us about the value of l_lambda? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b2c20-6695-4ad2-aba5-464dbd58198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valiues, l_lambda, ci = stats.boxcox(data.price, alpha = .05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4122ab0a-78dd-4049-808c-e3bbd70c01e8",
   "metadata": {},
   "source": [
    "## Compare the performance of a linear-log model against the linear-linear model using 5-fold cross validation. Use RMSE as the comparison metric.\n",
    "\n",
    "Sklearn is the premier machine learning library within python and has many tools within for model fitting, tuning, testing, and evaluation. It has an implementation of OLS within it that is equivalent to the statsmodels implementation and is compatible with the other tools within sklearn that are not implemented within statsmodels (such as cross validation). \n",
    "\n",
    "Here is a reference table of metrics that can be used with the \"scoring\" hyperparameter and the general situations in which they would be appropriate:\n",
    "\n",
    "| **Scoring Name**                         | **Description**                                                                                                                                     | **Applicable To**                |\n",
    "|------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------|\n",
    "| **accuracy**                             | Fraction of correct predictions ([`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)).         | Classification                   |\n",
    "| **balanced_accuracy**                    | Accuracy adjusted for class imbalance.                                                                                                              | Classification                   |\n",
    "| **average_precision**                    | Area under the precision-recall curve ([`average_precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html)). | Classification                   |\n",
    "| **neg_brier_score**                      | Negative Brier score loss (the lower the better).                                                                                                   | Probabilistic Classification     |\n",
    "| **f1**                                   | F1 score (harmonic mean of precision and recall).                                                                                                   | Binary Classification            |\n",
    "| **f1_macro**                             | F1 score (macro-average).                                                                                                                           | Multiclass Classification        |\n",
    "| **f1_micro**                             | F1 score (micro-average).                                                                                                                           | Multiclass Classification        |\n",
    "| **f1_weighted**                          | F1 score (weighted average).                                                                                                                        | Multiclass Classification        |\n",
    "| **f1_samples**                           | F1 score (by sample).                                                                                                                               | Multi-label Classification       |\n",
    "| **neg_log_loss**                         | Negative log-likelihood loss (the lower the better).                                                                                                | Probabilistic Classification     |\n",
    "| **precision**                            | Precision score.                                                                                                                                    | Binary Classification            |\n",
    "| **precision_macro**                      | Precision (macro-average).                                                                                                                          | Multiclass Classification        |\n",
    "| **precision_micro**                      | Precision (micro-average).                                                                                                                          | Multiclass Classification        |\n",
    "| **precision_weighted**                   | Precision (weighted average).                                                                                                                       | Multiclass Classification        |\n",
    "| **precision_samples**                    | Precision (by sample).                                                                                                                              | Multi-label Classification       |\n",
    "| **recall**                               | Recall score.                                                                                                                                       | Binary Classification            |\n",
    "| **recall_macro**                         | Recall (macro-average).                                                                                                                             | Multiclass Classification        |\n",
    "| **recall_micro**                         | Recall (micro-average).                                                                                                                             | Multiclass Classification        |\n",
    "| **recall_weighted**                      | Recall (weighted average).                                                                                                                          | Multiclass Classification        |\n",
    "| **recall_samples**                       | Recall (by sample).                                                                                                                                 | Multi-label Classification       |\n",
    "| **jaccard**                              | Jaccard similarity coefficient score.                                                                                                               | Binary Classification            |\n",
    "| **jaccard_macro**                        | Jaccard score (macro-average).                                                                                                                      | Multiclass Classification        |\n",
    "| **jaccard_micro**                        | Jaccard score (micro-average).                                                                                                                      | Multiclass Classification        |\n",
    "| **jaccard_weighted**                     | Jaccard score (weighted average).                                                                                                                   | Multiclass Classification        |\n",
    "| **jaccard_samples**                      | Jaccard score (by sample).                                                                                                                          | Multi-label Classification       |\n",
    "| **roc_auc**                              | Area under the ROC curve ([`roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)).                  | Binary Classification            |\n",
    "| **roc_auc_ovr**                          | ROC AUC with one-vs-rest multiclass strategy.                                                                                                       | Multiclass Classification        |\n",
    "| **roc_auc_ovo**                          | ROC AUC with one-vs-one multiclass strategy.                                                                                                        | Multiclass Classification        |\n",
    "| **roc_auc_ovr_weighted**                 | Weighted average of ROC AUC OVR.                                                                                                                    | Multiclass Classification        |\n",
    "| **roc_auc_ovo_weighted**                 | Weighted average of ROC AUC OVO.                                                                                                                    | Multiclass Classification        |\n",
    "| **explained_variance**                   | Explained variance regression score.                                                                                                                | Regression                       |\n",
    "| **max_error**                            | Maximum residual error.                                                                                                                             | Regression                       |\n",
    "| **neg_mean_absolute_error**              | Negative mean absolute error.                                                                                                                       | Regression                       |\n",
    "| **neg_mean_squared_error**               | Negative mean squared error.                                                                                                                        | Regression                       |\n",
    "| **neg_root_mean_squared_error**          | Negative root mean squared error.                                                                                                                   | Regression                       |\n",
    "| **neg_mean_squared_log_error**           | Negative mean squared logarithmic error.                                                                                                            | Regression                       |\n",
    "| **neg_median_absolute_error**            | Negative median absolute error.                                                                                                                     | Regression                       |\n",
    "| **r2**                                   | R<sup>2</sup> (coefficient of determination) regression score function.                                                                             | Regression                       |\n",
    "| **neg_mean_poisson_deviance**            | Negative mean Poisson deviance.                                                                                                                     | Regression (count data)          |\n",
    "| **neg_mean_gamma_deviance**              | Negative mean Gamma deviance.                                                                                                                       | Regression (positive data)       |\n",
    "| **neg_mean_absolute_percentage_error**   | Negative mean absolute percentage error.                                                                                                            | Regression                       |\n",
    "| **adjusted_mutual_info_score**           | Adjusted mutual information score.                                                                                                                  | Clustering                       |\n",
    "| **adjusted_rand_score**                  | Adjusted Rand index.                                                                                                                                | Clustering                       |\n",
    "| **completeness_score**                   | Completeness score.                                                                                                                                 | Clustering                       |\n",
    "| **fowlkes_mallows_score**                | Fowlkes-Mallows index.                                                                                                                              | Clustering                       |\n",
    "| **homogeneity_score**                    | Homogeneity score.                                                                                                                                  | Clustering                       |\n",
    "| **mutual_info_score**                    | Mutual information score.                                                                                                                           | Clustering                       |\n",
    "| **normalized_mutual_info_score**         | Normalized mutual information score.                                                                                                                | Clustering                       |\n",
    "| **v_measure_score**                      | V-measure (harmonic mean of homogeneity and completeness).                                                                                          | Clustering                       |\n",
    "| **rand_score**                           | Rand index adjusted for chance.                                                                                                                     | Clustering                       |\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "- For regression metrics prefixed with `neg_`, the negative sign indicates that the metric is reversed in sign so that higher values are better (since cross-validation aims to **maximize** the score). For example, `neg_mean_squared_error` returns the negative MSE, so maximizing the negative MSE minimizes the MSE.\n",
    "- Some metrics are suitable only for binary classification, while others can handle multiclass or multi-label problems.\n",
    "- The `roc_auc` metric by default is for binary classification. For multiclass classification, you can use `roc_auc_ovr` (one-vs-rest) or `roc_auc_ovo` (one-vs-one).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b447a-128f-4144-a7c4-a2b4bafe1c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn functions work best with their own implementations of models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a2b1d-c86c-4807-a65d-55e51aab037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X must be a Dataframe and y is A Series \n",
    "X = data[['sqrft']]\n",
    "Y = data['price']\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(model, X = X, y = Y,\n",
    "                        scoring = ___, # Preferred metric\n",
    "                         cv = ___) # Number of folds\n",
    "\n",
    "# here you need to complete the code to take the mean and convert to a postive value\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b17f45-de31-40fa-86dc-04401abec017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X must be a Dataframe and y is A Series \n",
    "X = ___\n",
    "Y = data['price']\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "scores = cross_val_score(model, X = X, y = Y,\n",
    "                        scoring = ___, # Preferred metric\n",
    "                         cv = ___) # Number of folds\n",
    "\n",
    "# here you need to complete the code to take the mean and convert to a postive value\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6880e0e-3399-4ade-8280-843ff90c1a24",
   "metadata": {},
   "source": [
    "## Question 8: Let's suppose we would like to add an additional regressor to our model \"colonial\".\n",
    "\n",
    "Please fit the following regression in statsmodels:\n",
    "\n",
    "$$price = \\beta_1 + \\beta_2 sqrft + \\beta_3 sqrft^2+ \\beta_3 colonial + e$$\n",
    "\n",
    "- What is special about the variable \"colonial\"?\n",
    "- What is the interpretation of the coefficient on \"colonial\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d5fcca-0bac-4edb-8d5e-70c5b7b3c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('___ ~ ___', data).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d8d30-6eee-40e0-a36f-0011b58bb484",
   "metadata": {},
   "source": [
    "## Question 8: Examine the following code where we plot the effect of sqrft on price and aswer the following:\n",
    "\n",
    "- Why do we fix the value of colonial at one value?\n",
    "- Why would we fix the value at the \"mode\"?\n",
    "- If we added another variable (such as bedrooms or lotsize), what value may make sense for us to fix them at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23acc0e0-df36-4ee5-b365-c23c2e2d8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a range of values for sqrft over which the model can make a prediction\n",
    "prediction_values = pd.DataFrame(np.linspace(data['sqrft'].min(), data['sqrft'].max(), 1000), columns = ['sqrft'])\n",
    "\n",
    "# below I add a fixed value for colonial\n",
    "prediction_values['colonial'] = data['colonial'].mode().values[0]\n",
    "y = model.predict(prediction_values)\n",
    "\n",
    "prediction_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0709d94-0e75-4565-a167-58f174295a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(prediction_values['sqrft'], y, color = 'black')\n",
    "plt.scatter(data['sqrft'], data['price'])\n",
    "plt.ylabel('price')\n",
    "plt.xlabel('sqrft')\n",
    "plt.title('Sqrft Effect Plot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
